{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依赖安装\n",
    "安装一些必须的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-01-28T06:05:37.455546Z",
     "iopub.status.busy": "2023-01-28T06:05:37.454880Z",
     "iopub.status.idle": "2023-01-28T06:06:22.467126Z",
     "shell.execute_reply": "2023-01-28T06:06:22.466134Z",
     "shell.execute_reply.started": "2023-01-28T06:05:37.455511Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/external-libraries\": 文件已存在\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.1.1)\r\n",
      "Collecting paddlenlp\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a5/de/3f20df026e48eae755ea06cbd587dd845767ac2d04e3bcf5e24cdb62cc4f/paddlenlp-2.5.0-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.96)\r\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.4.0)\r\n",
      "Collecting typer\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0d/44/56c3f48d2bb83d76f5c970aef8e2c3ebd6a832f09e3621c5395371fe6999/typer-0.7.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\r\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\r\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (3.20.0)\r\n",
      "Collecting datasets>=2.0.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/38/fe/1fd04859fbd0035c76fec4886a3667ce7dd43df76fd1ff9180244a201eb0/datasets-2.9.0-py3-none-any.whl (462 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 kB\u001b[0m \u001b[31m852.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting huggingface-hub>=0.11.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/41/76/50cd8ffb78fa5ef9b11e972ee92514aafd99790e838a1eafbde6a28b3962/huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m711.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\r\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.1)\r\n",
      "Collecting uvicorn\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/f3/f39ac8ac3bdf356b4934b8f7e56173e96681f67ef0cd92bd33a5059fae9e/uvicorn-0.20.0-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\r\n",
      "Collecting fastapi\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/89/adf4525d1870021b65ec562e83e9f46d96494ad95f238d0264ef1ab6b604/fastapi-0.89.1-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: rich in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (12.6.0)\r\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.3.3)\r\n",
      "Collecting aiohttp\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7a/48/7882af39221fee58e33eee6c8e516097e2331334a5937f54fe5b5b285d9e/aiohttp-3.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (948 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bd/64/f0d369ede0ca54fdd520bdee5086dbaf0af81dac53a2ce847bd1ec6e0bf1/fsspec-2023.1.0-py3-none-any.whl (143 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (5.1.2)\r\n",
      "Collecting responses<0.19\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2.24.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.1.5)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.19.5)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (10.0.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (4.2.0)\r\n",
      "Collecting xxhash\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7f/9f/8645235cc0913d54eb38599e9bfbd884de6f430cd1a3217530ccb6cc1800/xxhash-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.0.12)\r\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/6a/a3b9a51b886eeee570ddb32ae64a8d2fd00cd25cb1daaf82260188d2d1e4/pydantic-1.10.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting starlette==0.22.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1d/4e/30eda84159d5b3ad7fe663c40c49b16dd17436abe838f10a56c34bee44e8/starlette-0.22.0-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from starlette==0.22.0->fastapi->paddlenlp) (3.6.1)\r\n",
      "Requirement already satisfied: pillow==8.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlefsl->paddlenlp) (8.2.0)\r\n",
      "Collecting paddlefsl\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fb/4a/25d1959a8f1fe5ee400f32fc9fc8b56d4fd6fc25315e23c0171f6e705e2a/paddlefsl-1.1.0-py3-none-any.whl (101 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (2.13.0)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (0.9.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from typer->paddlenlp) (8.0.4)\r\n",
      "Collecting h11>=0.8\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.16.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (3.0.0)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (22.1.0)\r\n",
      "Collecting asynctest==0.13.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl (26 kB)\r\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\r\n",
      "Collecting multidict<7.0,>=4.5\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/e4/745fb4cc79b439b1c1d1f441f2aa65f6250b77052d2bf4d8d8b5970ee672/multidict-6.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b2/18/3b0eb2690b3bf4d340a221d0e76b6c5f4cac9d5dd37fb8c7b6ec25c2f510/frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m565.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Collecting charset-normalizer<3.0,>=2.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/51/a507c856293ab05cdc1db77ff4bc1268ddd39f29e7dc4919aa497f0adbec/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\r\n",
      "Collecting yarl<2.0,>=1.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/02/c6/13751bb69244e4835fa8192a20d1d1110091f717f1e1b0168320ed1a29c9/yarl-1.8.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.4/231.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.25.6)\r\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\r\n",
      "Installing collected packages: xxhash, urllib3, pydantic, multidict, h11, fsspec, frozenlist, charset-normalizer, asynctest, async-timeout, yarl, starlette, aiosignal, uvicorn, typer, responses, paddlefsl, huggingface-hub, fastapi, aiohttp, datasets, paddlenlp\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 1.25.6\r\n",
      "    Uninstalling urllib3-1.25.6:\r\n",
      "      Successfully uninstalled urllib3-1.25.6\r\n",
      "  Attempting uninstall: paddlefsl\r\n",
      "    Found existing installation: paddlefsl 1.0.0\r\n",
      "    Uninstalling paddlefsl-1.0.0:\r\n",
      "      Successfully uninstalled paddlefsl-1.0.0\r\n",
      "  Attempting uninstall: paddlenlp\r\n",
      "    Found existing installation: paddlenlp 2.1.1\r\n",
      "    Uninstalling paddlenlp-2.1.1:\r\n",
      "      Successfully uninstalled paddlenlp-2.1.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "parl 1.4.1 requires pyzmq==18.1.1, but you have pyzmq 23.2.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 asynctest-0.13.0 charset-normalizer-2.1.1 datasets-2.9.0 fastapi-0.89.1 frozenlist-1.3.3 fsspec-2023.1.0 h11-0.14.0 huggingface-hub-0.12.0 multidict-6.0.4 paddlefsl-1.1.0 paddlenlp-2.5.0 pydantic-1.10.4 responses-0.18.0 starlette-0.22.0 typer-0.7.0 urllib3-1.25.11 uvicorn-0.20.0 xxhash-3.2.0 yarl-1.8.2\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting trustai==0.1.5\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e2/7d/30695427906c3a820dc44f6f9563f467d34f2df7ee0502df29c7bb224bb6/trustai-0.1.5-py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting IPython\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7c/6a/1f1365f4bf9fcb349fcaa5b61edfcefa721aa13ff37c5631296b12fab8e5/ipython-7.34.0-py3-none-any.whl (793 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting tqdm\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/bb/849011636c4da2e44f1253cd927cfb20ada4374d8b3a4e425416e84900cc/tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting numpy\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/ad/ff3b21ebfe79a4d25b4a4f8e5cf9fd44a204adb6b33c09010f566f51027a/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting matplotlib\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ad/62/7b662284352867a86acfb636761ba351723fc3a235efd8397578d903413d/matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-learn\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bd/05/e561bc99a615b5c099c7a9355409e5e57c525a108f1c2e156abb005b90a6/scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/eb/37/791f1a6edd13c61cac85282368aa68cb0f3f164440fdf60032f2cc6ca34e/prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting setuptools>=18.5\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c2/8b/abb577ca6ab2c71814d535b1ed1464c5f4aaefe1a31bbeb85013eb9b2401/setuptools-66.1.1-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting pygments\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/42/d9d95cc461f098f204cd20c85642ae40fbff81f74c300341b8d0e0df14e0/Pygments-2.14.0-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting pickleshare\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\r\n",
      "Collecting jedi>=0.16\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/60/4acda63286ef6023515eb914543ba36496b8929cb7af49ecce63afde09c6/jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting decorator\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d5/50/83c593b07763e1161326b3b8c6686f0f4b0f24d5526546bee538c89837d6/decorator-5.1.1-py3-none-any.whl (9.1 kB)\r\n",
      "Collecting backcall\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4c/1c/ff6546b6c12603d8dd1070aa3c3d273ad4c07f5771689a7b69a550e8c951/backcall-0.2.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Collecting pexpect>4.3\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/39/7b/88dbb785881c28a102619d46423cb853b46dbccc70d3ac362d99773a78ce/pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting matplotlib-inline\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f2/51/c34d7a1d528efaae3d8ddb18ef45a41f284eacf9e514523b191b7d0872cc/matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\r\n",
      "Collecting traitlets>=4.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/fa/bd160e08ac7f656d818a0e40ff88e1a302b07ad2384864fb288db3c812fa/traitlets-5.8.1-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.8/116.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting python-dateutil>=2.7\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting cycler>=0.10\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5c/f9/695d6bedebd747e5eb0fe8fad57b72fdf25411273a39791cde838d5a8f51/cycler-0.11.0-py3-none-any.whl (6.4 kB)\r\n",
      "Collecting kiwisolver>=1.0.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/8f/8dbe2d4efc4c0b08ec67d6efb7cc31fbfd688c80afad85f65980633b0d37/kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e3/d9/e9bae85e84737e76ebbcbea13607236da0c0699baed0ae4f1151b728a608/fonttools-4.38.0-py3-none-any.whl (965 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting pyparsing>=2.2.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6c/10/a7d0fa5baea8fe7b50f448ab742f26f52b80bfca85ac2be9d35cdd9a3246/pyparsing-3.0.9-py3-none-any.whl (98 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting packaging>=20.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ed/35/a31aed2993e398f6b09a790a181a7927eb14610ee8bbf02dc14d31677f1c/packaging-23.0-py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pillow>=6.2.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/dc/8a/ee6c0ecdf39a5674881a9ea82b488751be6feb7723b62c7df64229d60f85/Pillow-9.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting scipy>=1.1.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/58/4f/11f34cfc57ead25752a7992b069c36f5d18421958ebd6466ecd849aeaf86/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\r\n",
      "Collecting joblib>=0.11\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/91/d4/3b4c8e5a30604df4c7518c562d4bf0502f2fa29221459226e140cf846512/joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/63/8011bd08a4111858f79d2b09aad86638490d62fbf881c44e434a6dfca87b/parso-0.8.3-py2.py3-none-any.whl (100 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting typing-extensions\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/8e/f1a0a5a76cfef77e1eb6004cb49e5f8d72634da638420b9ea492ce8305e8/typing_extensions-4.4.0-py3-none-any.whl (26 kB)\r\n",
      "Collecting ptyprocess>=0.5\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/22/a6/858897256d0deac81a172289110f31629fc4cee19b6f01283303e18c8db3/ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Collecting wcwidth\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/20/f4/c0584a25144ce20bfcf1aecd041768b8c762c1eb0aa77502a3f0baa83f11/wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\r\n",
      "Collecting six>=1.5\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: wcwidth, ptyprocess, pickleshare, backcall, typing-extensions, traitlets, tqdm, threadpoolctl, six, setuptools, pyparsing, pygments, prompt-toolkit, pillow, pexpect, parso, packaging, numpy, joblib, fonttools, decorator, cycler, scipy, python-dateutil, matplotlib-inline, kiwisolver, jedi, scikit-learn, matplotlib, IPython, trustai\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "python-lsp-server 1.5.0 requires ujson>=3.0.0, but you have ujson 1.35 which is incompatible.\r\n",
      "python-language-server 0.33.0 requires jedi<0.18.0,>=0.17.0, but you have jedi 0.18.2 which is incompatible.\r\n",
      "parl 1.4.1 requires pyzmq==18.1.1, but you have pyzmq 23.2.1 which is incompatible.\r\n",
      "moviepy 1.0.1 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed IPython-7.34.0 backcall-0.2.0 cycler-0.11.0 decorator-5.1.1 fonttools-4.38.0 jedi-0.18.2 joblib-1.2.0 kiwisolver-1.4.4 matplotlib-3.5.3 matplotlib-inline-0.1.6 numpy-1.21.6 packaging-23.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.4.0 prompt-toolkit-3.0.36 ptyprocess-0.7.0 pygments-2.14.0 pyparsing-3.0.9 python-dateutil-2.8.2 scikit-learn-1.0.2 scipy-1.7.3 setuptools-66.1.1 six-1.16.0 threadpoolctl-3.1.0 tqdm-4.64.1 traitlets-5.8.1 trustai-0.1.5 typing-extensions-4.4.0 wcwidth-0.2.6\r\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/jedi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/kiwisolver-1.4.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/ptyprocess-0.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/setuptools-66.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/joblib-1.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/fonttools-4.38.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/trustai-0.1.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/ipython-7.34.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/matplotlib-3.5.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/parso-0.8.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pexpect already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pygments already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/IPython already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/tests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/packaging-23.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pexpect-4.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/parso already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/threadpoolctl-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/prompt_toolkit already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/cycler.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/backcall-0.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/ptyprocess already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/matplotlib_inline-0.1.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/prompt_toolkit-3.0.36.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/cycler-0.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/matplotlib-3.5.3-py3.7-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/Pillow-9.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy-1.21.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/typing_extensions-4.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scikit_learn-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/trustai already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/traitlets-5.8.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/decorator-5.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scipy-1.7.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/decorator.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/python_dateutil-2.8.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/jedi-0.18.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/matplotlib_inline already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/traitlets already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/tqdm-4.64.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/backcall already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/Pygments-2.14.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pickleshare.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/wcwidth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/Pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pyparsing-3.0.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/wcwidth-0.2.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/pickleshare-0.7.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/aistudio/external-libraries\n",
    "# !pip3 install -U paddlepaddle-gpu\n",
    "!pip3 install -U paddlenlp\n",
    "!pip3 install trustai==0.1.5 -t /home/aistudio/external-libraries\n",
    "# !pip install trustai -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备\n",
    "#### 1）模型训练数据\n",
    "我们推荐使用LCQMC数据集训练中文相似度计算模型。Paddlenlp框架会自动下载及缓存训练数据集，默认缓存存储路径为\"~/.paddlenlp/datasets\"。如需修改训练数据，请参考『初始化工作』中DATASET_NAME的修改。\n",
    "#### 2）下载预训练模型\n",
    "基线使用了ERNIE-3.0-base预训练模型。Paddlenlp框架自动缓存模型文件，默认缓存存储路径为\"~/.paddlenlp/models\"。如需修改依赖的预训练模型，请在『初始化工作』中修改MODEL_NAME。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化工作\n",
    "初始化工作包括了模型选择及加载、训练数据集选择、模型存储路径设定、抽取证据的长度占原文本长度的比例设定等。可按需更改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-01-28T06:06:22.479764Z",
     "iopub.status.busy": "2023-01-28T06:06:22.479526Z",
     "iopub.status.idle": "2023-01-28T06:06:25.815641Z",
     "shell.execute_reply": "2023-01-28T06:06:25.814273Z",
     "shell.execute_reply.started": "2023-01-28T06:06:22.479742Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aistudio/external-libraries/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\r\n",
      "  \"Distutils was imported before Setuptools, but importing Setuptools \"\r\n",
      "/home/aistudio/external-libraries/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\r\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  _nlv = LooseVersion(_np_version)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  _np_version_under1p16 = _nlv < LooseVersion(\"1.16\")\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  _np_version_under1p17 = _nlv < LooseVersion(\"1.17\")\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  _np_version_under1p18 = _nlv < LooseVersion(\"1.18\")\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  _np_version_under1p19 = _nlv < LooseVersion(\"1.19\")\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  _np_version_under1p20 = _nlv < LooseVersion(\"1.20\")\r\n",
      "/home/aistudio/external-libraries/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  other = LooseVersion(other)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/compat/numpy/function.py:125: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "  if LooseVersion(_np_version) >= LooseVersion(\"1.17.0\"):\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/aistudio/work/trustai-pkg-paddle')\n",
    "sys.path.insert(0, '/home/aistudio/external-libraries')\n",
    "import json\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer\n",
    "\n",
    "# Select pre-trained model\n",
    "MODEL_NAME = \"ernie-3.0-base-zh\" # choose from [\"ernie-1.0\", \"ernie-1.0-base-zh\", \"ernie-1.0-large-zh-cw\", \"ernie-2.0-base-zh\", \"ernie-2.0-large-zh\", \"ernie-3.0-xbase-zh\", \"ernie-3.0-base-zh\", \"ernie-3.0-medium-zh\", \"ernie-3.0-mini-zh\", \"ernie-3.0-micro-zh\", \"ernie-3.0-nano-zh\"]\n",
    "# Select dataset for model training\n",
    "DATASET_NAME = 'lcqmc'\n",
    "# Set the path to save the trained model\n",
    "MODEL_SAVE_PATH = f'./save_model/{DATASET_NAME}-{MODEL_NAME}'\n",
    "# Set the rationale length ratio which determines the length of the extracted rationales.\n",
    "RATIONALE_RATIO = 0.705 # 0.705 for Chinese dataset, 0.508 for English dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-01-28T06:06:25.819017Z",
     "iopub.status.busy": "2023-01-28T06:06:25.818022Z",
     "iopub.status.idle": "2023-01-28T06:06:41.759791Z",
     "shell.execute_reply": "2023-01-28T06:06:41.758831Z",
     "shell.execute_reply.started": "2023-01-28T06:06:25.818980Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-28 14:06:25,821] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 2048,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 40000\r\n",
      "}\r\n",
      "\r\n",
      "[2023-01-28 14:06:25,825] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/config.json\r\n",
      "[2023-01-28 14:06:25,830] [    INFO] - Downloading ernie_3.0_base_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_base_zh.pdparams\r\n",
      "100%|██████████| 452M/452M [00:12<00:00, 37.6MB/s] \r\n",
      "W0128 14:06:40.580371   207 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0128 14:06:40.584110   207 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-01-28 14:06:41,492] [ WARNING] - Some weights of the model checkpoint at ernie-3.0-base-zh were not used when initializing ErnieForSequenceClassification: ['cls.predictions.transform.bias', 'cls.predictions.decoder_bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.layer_norm.bias', 'cls.predictions.transform.weight']\r\n",
      "- This IS expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "[2023-01-28 14:06:41,495] [ WARNING] - Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at ernie-3.0-base-zh and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "[2023-01-28 14:06:41,498] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_base_zh_vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh\r\n",
      "[2023-01-28 14:06:41,565] [    INFO] - Downloading ernie_3.0_base_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_base_zh_vocab.txt\r\n",
      "100%|██████████| 182k/182k [00:00<00:00, 2.34MB/s]\r\n",
      "[2023-01-28 14:06:41,751] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json\r\n",
      "[2023-01-28 14:06:41,754] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json\r\n"
     ]
    }
   ],
   "source": [
    "# Init model and tokenizer\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "这里以ERNIE-3.0为例训练一个文本相似度模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:28:59.236946Z",
     "iopub.status.busy": "2023-01-19T12:28:59.236651Z",
     "iopub.status.idle": "2023-01-19T12:29:01.416289Z",
     "shell.execute_reply": "2023-01-19T12:29:01.414726Z",
     "shell.execute_reply.started": "2023-01-19T12:28:59.236920Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6827/6827 [00:01<00:00, 4993.48it/s]\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "# Load dataset\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:29:01.418831Z",
     "iopub.status.busy": "2023-01-19T12:29:01.418435Z",
     "iopub.status.idle": "2023-01-19T12:29:01.431067Z",
     "shell.execute_reply": "2023-01-19T12:29:01.430242Z",
     "shell.execute_reply.started": "2023-01-19T12:29:01.418801Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trustai_pkg.prepare' from '/home/aistudio/work/trustai-pkg-paddle/trustai_pkg/prepare.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from trustai_pkg import prepare\n",
    "reload(prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:29:01.432359Z",
     "iopub.status.busy": "2023-01-19T12:29:01.432023Z",
     "iopub.status.idle": "2023-01-19T12:29:01.680784Z",
     "shell.execute_reply": "2023-01-19T12:29:01.680079Z",
     "shell.execute_reply.started": "2023-01-19T12:29:01.432335Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'query': '喜欢打篮球的男生喜欢什么样的女生', 'title': '爱打篮球的男生喜欢什么样的女生', 'label': 1},\n",
       " {'query': '开初婚未育证明怎么弄？', 'title': '初婚未育情况证明怎么开？', 'label': 1},\n",
       " {'query': '谁有狂三这张高清的', 'title': '这张高清图，谁有', 'label': ''})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0], dev_ds[0], test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:29:01.682356Z",
     "iopub.status.busy": "2023-01-19T12:29:01.681815Z",
     "iopub.status.idle": "2023-01-19T12:29:01.686824Z",
     "shell.execute_reply": "2023-01-19T12:29:01.686229Z",
     "shell.execute_reply.started": "2023-01-19T12:29:01.682331Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 原始字段需要移除\n",
    "remove_columns = ['source', 'target', 'id']\n",
    "# 文本的最大长度\n",
    "max_source_length = 128\n",
    "max_seq_length = 128\n",
    "# 摘要的最大长度\n",
    "max_target_length = 64\n",
    "\n",
    "\n",
    "model_set = prepare.ModelSet(tokenizer, model)\n",
    "prepare_config = prepare.SimilarityPrepareConfig(text_column=remove_columns[0], target_column=remove_columns[1],\n",
    "    max_seq_length=max_source_length, max_source_length=max_source_length, max_target_length=max_target_length, min_target_length=0, batch_size=12)\n",
    "\n",
    "prepare_tool = prepare.SimilarityPrepare(model_set, prepare_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:29:01.688111Z",
     "iopub.status.busy": "2023-01-19T12:29:01.687657Z",
     "iopub.status.idle": "2023-01-19T12:29:01.696372Z",
     "shell.execute_reply": "2023-01-19T12:29:01.695764Z",
     "shell.execute_reply.started": "2023-01-19T12:29:01.688087Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-19 20:29:01,690] [   DEBUG] - tt:<class 'paddlenlp.datasets.dataset.MapDataset'>\r\n",
      "[2023-01-19 20:29:01,692] [   DEBUG] - t:<class 'paddlenlp.datasets.dataset.MapDataset'>\r\n"
     ]
    }
   ],
   "source": [
    "train_ds, dev_ds, test_ds = prepare_tool.get_dataset(train_ds, dev_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:29:01.699467Z",
     "iopub.status.busy": "2023-01-19T12:29:01.699044Z",
     "iopub.status.idle": "2023-01-19T12:29:01.702623Z",
     "shell.execute_reply": "2023-01-19T12:29:01.702009Z",
     "shell.execute_reply.started": "2023-01-19T12:29:01.699443Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl, dev_dl, test_dl = prepare_tool.get_dataloader(train_ds, dev_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:29:01.703571Z",
     "iopub.status.busy": "2023-01-19T12:29:01.703351Z",
     "iopub.status.idle": "2023-01-19T12:29:01.706955Z",
     "shell.execute_reply": "2023-01-19T12:29:01.706272Z",
     "shell.execute_reply.started": "2023-01-19T12:29:01.703551Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 输出训练集的前 3 条样本\n",
    "# for idx, example in enumerate(dev_dl):\n",
    "#     if idx < 3:\n",
    "#         print(example) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:40:24.621999Z",
     "iopub.status.busy": "2023-01-19T12:40:24.621091Z",
     "iopub.status.idle": "2023-01-19T12:40:24.630236Z",
     "shell.execute_reply": "2023-01-19T12:40:24.629536Z",
     "shell.execute_reply.started": "2023-01-19T12:40:24.621967Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trustai_pkg.trainer' from '/home/aistudio/work/trustai-pkg-paddle/trustai_pkg/trainer.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trustai_pkg import trainer\n",
    "reload(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:40:24.810931Z",
     "iopub.status.busy": "2023-01-19T12:40:24.810139Z",
     "iopub.status.idle": "2023-01-19T12:40:24.818205Z",
     "shell.execute_reply": "2023-01-19T12:40:24.817498Z",
     "shell.execute_reply.started": "2023-01-19T12:40:24.810898Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_config = trainer.SimilarityTrainerConfig(\n",
    "    # 学习率预热比例\n",
    "    warmup = 0.02,\n",
    "    # 学习率\n",
    "    learning_rate = 5e-5,\n",
    "    # 训练轮次\n",
    "    num_epochs = 3,\n",
    "    # AdamW优化器参数epsilon\n",
    "    adam_epsilon = 1e-6,\n",
    "    # AdamW优化器参数weight_decay\n",
    "    weight_decay=0.01,\n",
    "    # 训练中，每个log_steps打印一次日志\n",
    "    log_steps = 100,\n",
    "    # 训练中，每隔eval_steps进行一次模型评估\n",
    "    eval_steps = 1000,\n",
    "    # 摘要的最小长度\n",
    "    min_target_length = 0,\n",
    "    # 训练模型保存路径\n",
    "    output_dir = 'checkpoints',\n",
    "    # 解码beam size\n",
    "    num_beams = 4,\n",
    "    log_dir = 'visualdl_log_dir'\n",
    ")\n",
    "\n",
    "trainer = trainer.SimilarityTrainer(train_dl, dev_dl, model_set, prepare_config, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:40:25.277888Z",
     "iopub.status.busy": "2023-01-19T12:40:25.276904Z",
     "iopub.status.idle": "2023-01-19T12:40:25.280918Z",
     "shell.execute_reply": "2023-01-19T12:40:25.280242Z",
     "shell.execute_reply.started": "2023-01-19T12:40:25.277850Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dl):\n",
    "#     if step > 0:\n",
    "#         break\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:40:25.967757Z",
     "iopub.status.busy": "2023-01-19T12:40:25.967013Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-19 21:05:55,513] [    INFO] - global step 100/59694, epoch: 0, batch: 99, rank_id: 0, loss: 0.700589, lr: 0.0000041911, speed: 0.0654 step/s\r\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要度分数获取\n",
    "该步为输入中每个词赋一个重要度分数，表示该词对预测的影响度。重要度分数获取共分三步。\n",
    "#### 1）加载模型和评测数据集\n",
    "更改模型以及评估数据的存储路径（MODEL_PATH和DATA_PATH），完成模型和评测数据集的加载。赛段一数据量为1712条，赛段二数据量为4167条，请确认评测数据集完整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T06:06:41.761286Z",
     "iopub.status.busy": "2023-01-28T06:06:41.761017Z",
     "iopub.status.idle": "2023-01-28T06:06:42.803260Z",
     "shell.execute_reply": "2023-01-28T06:06:42.802176Z",
     "shell.execute_reply.started": "2023-01-28T06:06:41.761261Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of data: 4167\r\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data\n",
    "\n",
    "# Correct MODEL_PATH and DATA_PATH before executing\n",
    "MODEL_PATH = MODEL_SAVE_PATH + '/model_state.pdparams'\n",
    "# MODEL_PATH = os.path.join(train_config.output_dir, 'model_state.pdparam')\n",
    "DATA_PATH = '/home/aistudio/similarity_ch/similarity_ch'\n",
    "\n",
    "# Load the trained parameters\n",
    "state_dict = paddle.load(MODEL_PATH)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "# Load test data\n",
    "data = load_data(DATA_PATH)\n",
    "print(\"Num of data:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2）数据预处理\n",
    "\n",
    "a) 输入格式化：将输入的两个文本组织成模型预测所需格式，如对于Ernie3.0-base模型，其输入形式为[CLS]query[SEP]title[SEP]\n",
    "\n",
    "b) 分词位置索引：计算每个分词结果对应的原文位置索引，这里的分词包括模型分词和标准分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T06:06:42.804689Z",
     "iopub.status.busy": "2023-01-28T06:06:42.804319Z",
     "iopub.status.idle": "2023-01-28T06:06:46.383982Z",
     "shell.execute_reply": "2023-01-28T06:06:46.383093Z",
     "shell.execute_reply.started": "2023-01-28T06:06:42.804662Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trustai.interpretation import get_word_offset\n",
    "\n",
    "# Add CLS and SEP tags to both original text and standard splited tokens\n",
    "contexts = []\n",
    "standard_split = []\n",
    "for idx in data:\n",
    "    example = data[idx]\n",
    "    contexts.append(\"[CLS]\" + example['query'] + \"[SEP]\" + example['title'] + \"[SEP]\")\n",
    "    standard_split.append([\"[CLS]\"] + example['text_q_seg'] + [\"[SEP]\"] + example['text_t_seg'] + [\"[SEP]\"])\n",
    "\n",
    "# Get the offset map of tokenized tokens and standard splited tokens\n",
    "ori_offset_maps = []\n",
    "standard_split_offset_maps = []\n",
    "for i in range(len(contexts)):\n",
    "    ori_offset_maps.append(tokenizer.get_offset_mapping(contexts[i]))\n",
    "    standard_split_offset_maps.append(get_word_offset(contexts[i], standard_split[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）重要度分数获取\n",
    "我们提供attention，IG，LIME等三种解释方法，可根据实际实验结果选取最有效的一种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a） Attention-based Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T06:06:46.385513Z",
     "iopub.status.busy": "2023-01-28T06:06:46.385089Z",
     "iopub.status.idle": "2023-01-28T06:07:06.724682Z",
     "shell.execute_reply": "2023-01-28T06:07:06.723762Z",
     "shell.execute_reply.started": "2023-01-28T06:06:46.385485Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level.common import attention_predict_fn_on_paddlenlp\n",
    "from trustai.interpretation.token_level import AttentionInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Init an attention interpreter and get the importance scores\n",
    "att = AttentionInterpreter(model, device=\"gpu\", predict_fn=attention_predict_fn_on_paddlenlp)\n",
    "\n",
    "# Use attention interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in create_dataloader_from_scratch(list(data.values()), tokenizer, BATCH_SIZE):\n",
    "    if interp_results:\n",
    "        interp_results += att(batch)\n",
    "    else:\n",
    "        interp_results = att(batch)\n",
    "\n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = att.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b）IG-based Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T06:09:52.429007Z",
     "iopub.status.busy": "2023-01-28T06:09:52.428074Z",
     "iopub.status.idle": "2023-01-28T06:40:50.912561Z",
     "shell.execute_reply": "2023-01-28T06:40:50.911586Z",
     "shell.execute_reply.started": "2023-01-28T06:09:52.428975Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level import IntGradInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "# Hyperparameters\n",
    "IG_STEP = 100\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Init an IG interpreter\n",
    "ig = IntGradInterpreter(model, device=\"gpu\")\n",
    "\n",
    "# Use IG interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in create_dataloader_from_scratch(list(data.values()), tokenizer, BATCH_SIZE):\n",
    "    if interp_results:\n",
    "        interp_results += ig(batch, steps=IG_STEP)\n",
    "    else:\n",
    "        interp_results = ig(batch, steps=IG_STEP)\n",
    "\n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = ig.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c）LIME Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T06:40:50.933633Z",
     "iopub.status.busy": "2023-01-28T06:40:50.933327Z",
     "iopub.status.idle": "2023-01-28T07:41:08.116312Z",
     "shell.execute_reply": "2023-01-28T07:41:08.115264Z",
     "shell.execute_reply.started": "2023-01-28T06:40:50.933609Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from trustai.interpretation.token_level import LIMEInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "# Hyperparameters\n",
    "LIME_SAMPLES = 1000\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Init an LIME interpreter\n",
    "lime = LIMEInterpreter(model, device=\"gpu\",\n",
    "    unk_id=tokenizer.convert_tokens_to_ids('[UNK]'),\n",
    "    pad_id=tokenizer.convert_tokens_to_ids('[PAD]'))\n",
    "\n",
    "# Use LIME interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in create_dataloader_from_scratch(list(data.values()), tokenizer, BATCH_SIZE):\n",
    "    if interp_results:\n",
    "        interp_results += lime(batch, num_samples=LIME_SAMPLES)\n",
    "    else:\n",
    "        interp_results = lime(batch, num_samples=LIME_SAMPLES)\n",
    "    \n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = lime.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成用于评估的数据\n",
    "评估文件格式要求是4列数据：编号\\t预测标签\\t证据1\\t证据2，我们提供了脚本将模型输出结果转成评估所需格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T07:41:08.120095Z",
     "iopub.status.busy": "2023-01-28T07:41:08.119800Z",
     "iopub.status.idle": "2023-01-28T07:41:08.283245Z",
     "shell.execute_reply": "2023-01-28T07:41:08.282302Z",
     "shell.execute_reply.started": "2023-01-28T07:41:08.120068Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Re-sort the token index according to their importance scores\n",
    "def resort(index_array, importance_score):\n",
    "    res = sorted([[idx, importance_score[idx]] for idx in index_array], key=lambda x:x[1], reverse=True)\n",
    "    res = [n[0] for n in res]\n",
    "    return res\n",
    "\n",
    "# Post-prepare the result data so that it can be used for the evaluation directly\n",
    "def prepare_eval_data(data, results, paddle_model):\n",
    "    res = {}\n",
    "    for data_id, inter_res in zip(data, results):\n",
    "        # Split importance score vectors for query and title from inter_res.word_attributions\n",
    "        query_importance_score = np.array(inter_res.word_attributions[1:len(data[data_id]['text_q_seg'])+1])\n",
    "        title_importance_score = np.array(inter_res.word_attributions[len(data[data_id]['text_q_seg'])+2:-1])\n",
    "        # Extract topK importance scores\n",
    "        query_topk = math.ceil(len(data[data_id]['text_q_seg'])*RATIONALE_RATIO)\n",
    "        title_topk = math.ceil(len(data[data_id]['text_t_seg'])*RATIONALE_RATIO)\n",
    "        \n",
    "        eval_data = {}        \n",
    "        eval_data['id'] = data_id\n",
    "        eval_data['pred_label'] = inter_res.pred_label\n",
    "        # Find the token index of the topK importance scores\n",
    "        eval_data['rationale_q'] = np.argpartition(query_importance_score, -query_topk)[-query_topk:]\n",
    "        eval_data['rationale_t'] = np.argpartition(title_importance_score, -title_topk)[-title_topk:]\n",
    "        # Re-sort the token index according to their importance scores\n",
    "        eval_data['rationale_q'] = resort(eval_data['rationale_q'], query_importance_score)\n",
    "        eval_data['rationale_t'] = resort(eval_data['rationale_t'], title_importance_score)\n",
    "\n",
    "        res[data_id] = eval_data\n",
    "    return res\n",
    "\n",
    "# Generate results for evaluation\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "out_file = open('./sim_rationale.txt', 'w')\n",
    "for key in predicts:\n",
    "    out_file.write(str(predicts[key]['id'])+'\\t'+ str(predicts[key]['pred_label'])+'\\t')\n",
    "    for idx in predicts[key]['rationale_q'][:-1]:\n",
    "        out_file.write(str(idx)+',')\n",
    "    out_file.write(str(predicts[key]['rationale_q'][-1])+'\\t')\n",
    "\n",
    "    for idx in predicts[key]['rationale_t'][:-1]:\n",
    "        out_file.write(str(idx)+',')\n",
    "    out_file.write(str(predicts[key]['rationale_t'][-1])+'\\n')\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
